{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "MP4w9g1dwOzr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9jvkNyEvxnW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from IPython import embed\n",
        "from skimage import color\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "4-r0iLRVwTDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Pre processing of data to index rbg training data\n",
        "\n",
        "def preProcessing(path, h=256, w=256):\n",
        "  if not os.path.exists(path + \"/train\"):\n",
        "    os.mkdir(path + \"/train\")\n",
        "    os.mkdir(path + \"/train/rgb\")\n",
        "\n",
        "  idx=0\n",
        "  for filename in os.listdir(path):\n",
        "    if not os.path.isdir(path + \"/\" + filename):\n",
        "      \n",
        "      #get RGB image, resize, and put in rgb folder\n",
        "      rgb_img=Image.open(path + \"/\" + filename)\n",
        "      rgb_img=rgb_img.resize((w, h))\n",
        "      rgb_img.save(path + \"/train/target/\" + str(idx) + \"_rgb.png\")\n",
        "\n",
        "      idx+=1\n"
      ],
      "metadata": {
        "id": "8dVwHNj-wU4X"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Scafolding for Dataset\n",
        "\n",
        "def myDataset(h=256, w=256, rgb2lab=True, zhangmodel=True, edmodel=False):\n",
        "  def __init__(self, img_dir, transform):\n",
        "    self.img_dir=img_dir\n",
        "    self.transform=transform\n",
        "    self.dataset_length = len(os.listdir(img_dir + \"/train/rgb\"))\n",
        "    \n",
        "    #Set up dataset so images are indexed\n",
        "    preProcessing(img_dir, h, w)\n",
        "\n",
        "    if zhangmodel:\n",
        "      print(\"ZHANG MODEL\")\n",
        "\n",
        "    elif edmodel:\n",
        "      print(\"ED MODEL\")\n",
        "\n",
        "    def __len__(self):\n",
        "      return self.dataset_length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      #Get RGB image, resize, and transform it\n",
        "      rgb_img=Image.open(self.img_dir + \"/\" + str(idx) + \"_rgb.png\")\n",
        "      rgb_img=self.transform(rgb_img.resize((w, h)))\n",
        "\n",
        "      #Get CIE-Lab equivalent of the RGB image\n",
        "      clab_array=color.rgb2lab(np.asarray(rgb_img))\n",
        "      clab_img=Image.fromarray(clab_array, mode=\"LAB\")\n",
        "\n",
        "      #Get greyscale CIE-Lab equivalent of the RGB image\n",
        "      clab_grayimg=Image.fromarray(clab_array[:, :, 0], mode=\"LAB\")\n",
        "\n",
        "      data={'input':clab_grayimg, 'target':clab_img}\n",
        "\n",
        "      return data\n",
        "    "
      ],
      "metadata": {
        "id": "2zK_YyGcwVP6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 1 (\"Colorful Image Colorization\" by Zhang et al.)"
      ],
      "metadata": {
        "id": "QerlomvDwVor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseModel(nn.Module):\n",
        "  '''\n",
        "  A 8-blocks cnn model, each block has multiple cnn layer (22 in total)\n",
        "  \"prediction\" in CIELAB space (L, a, b)\n",
        "  For this model, it takes in \"grayscale image\" with only L value\n",
        "  and it outputs a and b values\n",
        "  '''\n",
        "  def __init__(self, norm_layer = nn.BatchNorm2d):\n",
        "    super(BaseModel, self).__init__()\n",
        "    # layer 1\n",
        "    self.layer1 = nn.Sequential([\n",
        "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=True),\n",
        "            nn.ReLU(True),\n",
        "            norm_layer(64)])\n",
        "\n",
        "    # layer 2\n",
        "    self.layer2 = nn.Sequential([\n",
        "        nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1, bias=True),\n",
        "        nn.ReLU(True),\n",
        "        norm_layer(128)])\n",
        "\n",
        "    # layer 3\n",
        "    self.layer3 = nn.Sequential([\n",
        "        nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1, bias=True),\n",
        "        nn.ReLU(True),\n",
        "        norm_layer(256)])\n",
        "\n",
        "    # layer 4\n",
        "    self.layer4 = nn.Sequential([\n",
        "        nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "        nn.ReLU(True),\n",
        "        norm_layer(512)])\n",
        "\n",
        "    # layer 5\n",
        "    self.layer5 = nn.Sequential([\n",
        "        nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),\n",
        "        nn.ReLU(True),\n",
        "        norm_layer(512)])\n",
        "\n",
        "    #layer 6\n",
        "    self.layer6 = nn.Sequential([\n",
        "        nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),\n",
        "        nn.ReLU(True),\n",
        "        norm_layer(512),])\n",
        "\n",
        "    #layer 7\n",
        "    self.layer7 = nn.Sequential([\n",
        "        nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "        nn.ReLU(True),\n",
        "        norm_layer(512),])\n",
        "\n",
        "    #layer 8\n",
        "    self.layer8 = nn.Sequential([\n",
        "        nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=True),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(256, 313, kernel_size=1, stride=1, padding=0, bias=True),])\n",
        "\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "    # 2 means (a, b)\n",
        "    self.model_out = nn.Conv2d(313, 2, kernel_size=1, padding=0, dilation=1, stride=1, bias=False)\n",
        "    self.upsample = nn.Upsample(scale_factor=4, mode='bilinear')\n",
        "\n",
        "  def forward(self, input_l):\n",
        "    # model\n",
        "    conv1_2 = self.layer1(self.normalize_l(input_l))\n",
        "    conv2_2 = self.layer2(conv1_2)\n",
        "    conv3_3 = self.layer3(conv2_2)\n",
        "    conv4_3 = self.layer4(conv3_3)\n",
        "    conv5_3 = self.layer5(conv4_3)\n",
        "    conv6_3 = self.layer6(conv5_3)\n",
        "    conv7_3 = self.layer7(conv6_3)\n",
        "    conv8_3 = self.layer8(conv7_3)\n",
        "\n",
        "    out_reg = self.model_out(self.softmax(conv8_3))\n",
        "\n",
        "    # this is deal with nomalization\n",
        "    # output is in [0,1] (ratio of a, b to L)\n",
        "    # L ususally has a range [0, 100] (or 110)\n",
        "    return 100*(self.upsample(out_reg))"
      ],
      "metadata": {
        "id": "LEW1sIn5xsx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 1 Loss"
      ],
      "metadata": {
        "id": "j1N3H9IqG2UW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def RebalanceLoss"
      ],
      "metadata": {
        "id": "33iGi04v_A-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GetClassWeights"
      ],
      "metadata": {
        "id": "PJWQvrojG9D8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}